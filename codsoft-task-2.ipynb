{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45e6c62-cfb8-4fae-934f-5bb528a5d230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the dataset:\n",
      "Index(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category',\n",
      "       'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip',\n",
      "       'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time',\n",
      "       'merch_lat', 'merch_long', 'is_fraud'],\n",
      "      dtype='object')\n",
      "\n",
      "Here are the first few rows of the dataset:\n",
      "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
      "0           0   2020-06-21 12:14:25  2291163933867244   \n",
      "1           1   2020-06-21 12:14:33  3573030041201292   \n",
      "2           2   2020-06-21 12:14:53  3598215285024754   \n",
      "3           3   2020-06-21 12:15:15  3591919803438423   \n",
      "4           4   2020-06-21 12:15:17  3526826139003047   \n",
      "\n",
      "                               merchant        category    amt   first  \\\n",
      "0                 fraud_Kirlin and Sons   personal_care   2.86    Jeff   \n",
      "1                  fraud_Sporer-Keebler   personal_care  29.84  Joanne   \n",
      "2  fraud_Swaniawski, Nitzsche and Welch  health_fitness  41.28  Ashley   \n",
      "3                     fraud_Haley Group        misc_pos  60.05   Brian   \n",
      "4                 fraud_Johnston-Casper          travel   3.19  Nathan   \n",
      "\n",
      "       last gender                       street  ...      lat      long  \\\n",
      "0   Elliott      M            351 Darlene Green  ...  33.9659  -80.9355   \n",
      "1  Williams      F             3638 Marsh Union  ...  40.3207 -110.4360   \n",
      "2     Lopez      F         9333 Valentine Point  ...  40.6729  -73.5365   \n",
      "3  Williams      M  32941 Krystal Mill Apt. 552  ...  28.5697  -80.8191   \n",
      "4    Massey      M     5783 Evan Roads Apt. 465  ...  44.2529  -85.0170   \n",
      "\n",
      "   city_pop                     job         dob  \\\n",
      "0    333497     Mechanical engineer  1968-03-19   \n",
      "1       302  Sales professional, IT  1990-01-17   \n",
      "2     34496       Librarian, public  1970-10-21   \n",
      "3     54767            Set designer  1987-07-25   \n",
      "4      1126      Furniture designer  1955-07-06   \n",
      "\n",
      "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
      "0  2da90c7d74bd46a0caf3777415b3ebd3  1371816865  33.986391  -81.200714   \n",
      "1  324cc204407e99f51b0d6ca0055005e7  1371816873  39.450498 -109.960431   \n",
      "2  c81755dbbbea9d5c77f094348a7579be  1371816893  40.495810  -74.196111   \n",
      "3  2159175b9efe66dc301f149d3d5abf8c  1371816915  28.812398  -80.883061   \n",
      "4  57ff021bd3f328f8738bb535c302a31b  1371816917  44.959148  -85.884734   \n",
      "\n",
      "   is_fraud  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "The dataset contains 555719 rows and 23 columns.\n",
      "No target column found in the dataset. Please ensure the dataset contains a 'Class' or similar column indicating fraud cases.\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix\n",
    "\n",
    "# Load the dataset (Make sure to replace the path with the correct one on your system)\n",
    "data_path = r\"C:\\Users\\SYED ANAS\\Downloads\\fraudTest.csv\\fraudTest.csv\"\n",
    "try:\n",
    "    data = pd.read_csv(data_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"The file was not found. Please check the path and try again.\")\n",
    "    data = None\n",
    "\n",
    "if data is not None:\n",
    "    # Let's take a look at the column names to understand our dataset better\n",
    "    print(\"Column names in the dataset:\")\n",
    "    print(data.columns)\n",
    "\n",
    "    # Showing the first few rows of our dataset\n",
    "    print(\"\\nHere are the first few rows of the dataset:\")\n",
    "    print(data.head())\n",
    "\n",
    "    # Checking the dimensions of our dataset\n",
    "    print(f\"\\nThe dataset contains {data.shape[0]} rows and {data.shape[1]} columns.\")\n",
    "\n",
    "    # We need to find the target column that indicates fraud cases\n",
    "    potential_target_columns = ['Class', 'class', 'Target', 'target', 'Fraud', 'fraud']\n",
    "    target_column = None\n",
    "    for col in potential_target_columns:\n",
    "        if col in data.columns:\n",
    "            target_column = col\n",
    "            break\n",
    "\n",
    "    # If no target column is found, we skip further processing\n",
    "    if target_column is None:\n",
    "        print(\"No target column found in the dataset. Please ensure the dataset contains a 'Class' or similar column indicating fraud cases.\")\n",
    "    else:\n",
    "        # Identifying the number of fraud and valid cases\n",
    "        fraud_cases = data[data[target_column] == 1]\n",
    "        valid_cases = data[data[target_column] == 0]\n",
    "        outlier_fraction = len(fraud_cases) / float(len(valid_cases))\n",
    "        print(f\"\\nOutlier fraction (fraud cases to valid transactions): {outlier_fraction:.4f}\")\n",
    "        print(f\"Number of fraud cases: {len(fraud_cases)}\")\n",
    "        print(f\"Number of valid transactions: {len(valid_cases)}\")\n",
    "\n",
    "        # If there's an 'Amount' column, let's check out the stats for fraudulent and valid transactions\n",
    "        if 'Amount' in data.columns:\n",
    "            print(\"\\nDetails of fraudulent transactions:\")\n",
    "            print(fraud_cases['Amount'].describe())\n",
    "            print(\"\\nDetails of valid transactions:\")\n",
    "            print(valid_cases['Amount'].describe())\n",
    "        else:\n",
    "            print(\"'Amount' column not found in the dataset. Skipping amount statistics.\")\n",
    "\n",
    "        # Creating a correlation matrix to understand the relationships between variables\n",
    "        print(\"\\nGenerating a correlation matrix to understand the relationships between variables...\")\n",
    "        correlation_matrix = data.corr()\n",
    "        plt.figure(figsize=(12, 9))\n",
    "        sns.heatmap(correlation_matrix, vmax=.8, square=True, cmap='coolwarm')\n",
    "        plt.title(\"Correlation Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "        # Splitting the data into features (X) and the target variable (Y)\n",
    "        X = data.drop([target_column], axis=1)\n",
    "        Y = data[target_column]\n",
    "        print(f\"\\nFeatures shape: {X.shape}\")\n",
    "        print(f\"Target shape: {Y.shape}\")\n",
    "\n",
    "        # Splitting the data into training and testing sets\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X.values, Y.values, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Building the Random Forest Classifier\n",
    "        print(\"\\nTraining the Random Forest Classifier...\")\n",
    "        rfc = RandomForestClassifier(random_state=42)\n",
    "        rfc.fit(X_train, Y_train)\n",
    "\n",
    "        # Making predictions on the test set\n",
    "        print(\"\\nMaking predictions on the test set...\")\n",
    "        Y_pred = rfc.predict(X_test)\n",
    "\n",
    "        # Evaluating the classifier using different metrics\n",
    "        print(\"\\nEvaluating the classifier...\")\n",
    "        accuracy = accuracy_score(Y_test, Y_pred)\n",
    "        precision = precision_score(Y_test, Y_pred)\n",
    "        recall = recall_score(Y_test, Y_pred)\n",
    "        f1 = f1_score(Y_test, Y_pred)\n",
    "        mcc = matthews_corrcoef(Y_test, Y_pred)\n",
    "\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "        print(f\"Matthews correlation coefficient: {mcc:.4f}\")\n",
    "\n",
    "        # Generating the confusion matrix to visualize the performance of our model\n",
    "        print(\"\\nGenerating the confusion matrix...\")\n",
    "        labels = ['Valid', 'Fraud']\n",
    "        conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, xticklabels=labels, yticklabels=labels, annot=True, fmt=\"d\", cmap='Blues')\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.ylabel('True Class')\n",
    "        plt.xlabel('Predicted Class')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9068fba3-c9ce-4192-ac5c-369c56e38560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
